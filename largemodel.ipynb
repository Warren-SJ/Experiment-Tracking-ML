{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts import data_acquisition, data_setup, engine, plot_loss_curves, utils, model_acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_weights = models.EfficientNet_B2_Weights.DEFAULT\n",
    "efficientnet_transforms = efficientnet_weights.transforms()\n",
    "efficientnet_model = models.efficientnet_b2(weights=efficientnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_weights = models.ResNet18_Weights.DEFAULT\n",
    "resnet18_transforms = resnet18_weights.transforms()\n",
    "resnet18_model = models.resnet18(weights=resnet18_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_weights = models.ResNet152_Weights.DEFAULT\n",
    "resnet152_transforms = resnet152_weights.transforms()\n",
    "resnet152_model = models.resnet152(weights=resnet152_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weights = models.ViT_B_16_Weights.DEFAULT\n",
    "vit_transforms = vit_weights.transforms()\n",
    "vitb16_model = models.vit_b_16(weights=vit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to download the dataset\n",
    "traindataset = datasets.Food101(root = 'data', download = True, transform = None, split = \"train\")\n",
    "testdataset = datasets.Food101(root = 'data', download = True, transform = None, split = \"test\")\n",
    "print(len(traindataset), len(testdataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in efficientnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "# print(summary(efficientnet_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))\n",
    "efficientnet_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1408, out_features=101, bias=True)\n",
    ")\n",
    "# print(summary(efficientnet_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet18_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# print(summary(resnet18_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "resnet18_model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "# print(summary(resnet18_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet152_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# print(summary(resnet152_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "resnet152_model.fc =  nn.Linear(in_features=2048, out_features=101, bias=True)\n",
    "# print(summary(resnet152_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vitb16_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# print(summary(vitb16_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "vitb16_model.heads.head = nn.Linear(in_features=768, out_features=101, bias=True)\n",
    "# print(summary(vitb16_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.CIFAR10(root = 'data', download = True, split = \"train\", transform = efficientnet_transforms)\n",
    "testdataset = datasets.CIFAR10(root = 'data', download = True,  split = \"test\", transform = efficientnet_transforms)\n",
    "print(efficientnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(dataset = traindataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,)\n",
    "\n",
    "testdataloader = DataLoader(dataset = testdataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, all_preds, all_labels, writer = engine.train(model = efficientnet_model.to(device),\n",
    "                                                    model_name = \"efficientnet\",\n",
    "                                                    data_name=\"Food101\",\n",
    "                                                    epochs = EPOCHS,\n",
    "                                                    train_dataloader=traindataloader,\n",
    "                                                    val_dataloader = testdataloader,\n",
    "                                                    device = device,\n",
    "                                                    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                                                    optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_model.state_dict(), 'efficientnet_model_Food101.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.CIFAR10(root = 'data', download = True, split = \"train\", transform = resnet18_transforms)\n",
    "testdataset = datasets.CIFAR10(root = 'data', download = True, split = \"test\", transform = resnet18_transforms)\n",
    "print(efficientnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(dataset = traindataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,)\n",
    "\n",
    "testdataloader = DataLoader(dataset = testdataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, all_preds, all_labels, writer = engine.train(model = resnet18_model.to(device),\n",
    "                                                    model_name = \"resnet_18\",\n",
    "                                                    data_name=\"Food101\",\n",
    "                                                    epochs = EPOCHS,\n",
    "                                                    train_dataloader=traindataloader,\n",
    "                                                    val_dataloader = testdataloader,\n",
    "                                                    device = device,\n",
    "                                                    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                                                    optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_model.state_dict(), 'resnet_18_model_Food101.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Resnet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.CIFAR10(root = 'data', download = True, split = \"train\", transform = resnet18_transforms)\n",
    "testdataset = datasets.CIFAR10(root = 'data', download = True, split = \"test\", transform = resnet18_transforms)\n",
    "print(efficientnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(dataset = traindataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,)\n",
    "\n",
    "testdataloader = DataLoader(dataset = testdataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, all_preds, all_labels, writer = engine.train(model = resnet18_model.to(device),\n",
    "                                                    model_name = \"resnet_18\",\n",
    "                                                    data_name=\"Food101\",\n",
    "                                                    epochs = EPOCHS,\n",
    "                                                    train_dataloader=traindataloader,\n",
    "                                                    val_dataloader = testdataloader,\n",
    "                                                    device = device,\n",
    "                                                    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                                                    optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ViT B 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.CIFAR10(root = 'data', download = True, split = \"train\", transform = vit_transforms)\n",
    "testdataset = datasets.CIFAR10(root = 'data', download = True, split = \"test\", transform = vit_transforms)\n",
    "print(efficientnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(dataset = traindataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,)\n",
    "\n",
    "testdataloader = DataLoader(dataset = testdataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, all_preds, all_labels, writer = engine.train(model = resnet152_model.to(device),\n",
    "                                                    model_name = \"vit_b_16\",\n",
    "                                                    data_name=\"Food101\",\n",
    "                                                    epochs = EPOCHS,\n",
    "                                                    train_dataloader=traindataloader,\n",
    "                                                    val_dataloader = testdataloader,\n",
    "                                                    device = device,\n",
    "                                                    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                                                    optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_model.state_dict(), 'vit_b_16_model_Food101.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
