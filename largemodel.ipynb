{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts import data_acquisition, data_setup, engine, plot_loss_curves, utils, model_acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_weights = models.EfficientNet_B2_Weights.DEFAULT\n",
    "efficientnet_transforms = efficientnet_weights.transforms()\n",
    "efficientnet_model = models.efficientnet_b2(weights=efficientnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_weights = models.ResNet18_Weights.DEFAULT\n",
    "resnet18_transforms = resnet18_weights.transforms()\n",
    "resnet18_model = models.resnet18(weights=resnet18_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_weights = models.ResNet152_Weights.DEFAULT\n",
    "resnet152_transforms = resnet152_weights.transforms()\n",
    "resnet152_model = models.resnet152(weights=resnet152_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weights = models.ViT_B_16_Weights.DEFAULT\n",
    "vit_transforms = vit_weights.transforms()\n",
    "vitb16_model = models.vit_b_16(weights=vit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to download the dataset\n",
    "traindataset = datasets.Food101(root = 'data', download = True, transform = None, split='train')\n",
    "testdataset = datasets.Food101(root = 'data', download = True, transform = None, split='test')\n",
    "print(len(traindataset), len(testdataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in efficientnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "# print(summary(efficientnet_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))\n",
    "efficientnet_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1408, out_features=101, bias=True)\n",
    ")\n",
    "# print(summary(efficientnet_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet18_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# print(summary(resnet18_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "resnet18_model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "# print(summary(resnet18_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet152_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# print(summary(resnet152_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "resnet152_model.fc =  nn.Linear(in_features=2048, out_features=101, bias=True)\n",
    "# print(summary(resnet152_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vitb16_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# print(summary(vitb16_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\")))\n",
    "vitb16_model.heads.head = nn.Linear(in_features=768, out_features=101, bias=True)\n",
    "# print(summary(vitb16_model, input_size=(32, 3, 224, 224),col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:nn.Module,\n",
    "               transforms:transforms.Compose,\n",
    "               traindataloader:DataLoader,\n",
    "               testdataloader:DataLoader,\n",
    "               loss_fn:nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               ):\n",
    "    train_loss, train_correct = 0, 0\n",
    "    total_samples = 0\n",
    "    test_loss, test_correct = 0, 0 \n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(traindataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        total_samples += y.size(0)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        batch_correct = torch.sum(torch.argmax(y_pred, dim=1) == y).item()\n",
    "        train_correct += batch_correct\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(i%100==0):\n",
    "            print(f\"Batch {i} : Loss {loss.item()} : Accuracy {batch_correct/y.size(0)}\")\n",
    "    train_accuracy  = train_correct/len(traindataloader)\n",
    "    train_loss /= len(traindataloader)\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    with torch.inference_mode():\n",
    "        for x, y in testdataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            total_samples += y.size(0)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            batch_correct = torch.sum(torch.argmax(y_pred, dim=1) == y).item()\n",
    "            test_correct += batch_correct\n",
    "        test_accuracy = test_correct/total_samples\n",
    "        test_loss /= len(testdataloader) \n",
    "    return {\"train loss\" : train_loss,\n",
    "            \"train accuracy\" : train_accuracy,\n",
    "            \"test loss\" : test_loss,\n",
    "            \"test accuracy\" : test_accuracy\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:nn.Module,\n",
    "        transforms:transforms.Compose,\n",
    "        traindataloader:DataLoader,\n",
    "        testdataloader:DataLoader,\n",
    "        loss_fn:nn.Module,\n",
    "        epochs:int,\n",
    "        optimizer:torch.optim.Optimizer,):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        results = train_step(model, transforms, traindataloader, testdataloader, loss_fn, optimizer)\n",
    "        print(f\"Train Loss: {results['train loss']:.4f}, Train Accuracy: {results['train accuracy']:.4f}, Test Loss: {results['test loss']:.4f}, Test Accuracy: {results['test accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.Food101(root = 'data', download = True, split='train', transform = efficientnet_transforms)\n",
    "testdataset = datasets.Food101(root = 'data', download = True, split='test', transform = efficientnet_transforms)\n",
    "print(efficientnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(dataset = traindataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,)\n",
    "\n",
    "testdataloader = DataLoader(dataset = testdataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model = efficientnet_model,\n",
    "        transforms = efficientnet_transforms,\n",
    "        traindataloader = traindataloader,\n",
    "        testdataloader = testdataloader,\n",
    "        loss_fn = nn.CrossEntropyLoss(),\n",
    "        epochs = 10,\n",
    "        optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, all_preds, all_labels, writer = engine.train(model = efficientnet_model.to(device),\n",
    "                                                    model_name = \"efficientnet\",\n",
    "                                                    data_name=\"food101\",\n",
    "                                                    epochs = 10,\n",
    "                                                    train_dataloader=traindataloader,\n",
    "                                                    val_dataloader = testdataloader,\n",
    "                                                    device = device,\n",
    "                                                    loss_fn = nn.CrossEntropyLoss(),\n",
    "                                                    optimizer = torch.optim.Adam(efficientnet_model.parameters())\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_model.state_dict(), 'efficientnet_model_foodvision.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
